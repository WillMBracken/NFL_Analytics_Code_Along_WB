{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Module 04: The Prediction Machine\n",
        "\n",
        "## We've Built Our Dataset\n",
        "\n",
        "From our previous modules:\n",
        "1. **QB Efficiency** ‚Äî From play-by-play EPA (Expected Points Added)\n",
        "2. **QB Talent** ‚Äî From Madden ratings (the \"Oracle\")\n",
        "\n",
        "Now we feed this into a **Logistic Regression** model and predict the Super Bowl! üèÜ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import polars as pl\n",
        "from pathlib import Path\n",
        "import sys\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "PROJECT_ROOT = Path.cwd()\n",
        "sys.path.insert(0, str(PROJECT_ROOT / \"src\"))\n",
        "\n",
        "from ingestion import load_pbp_cached, load_schedules_cached\n",
        "from features import build_super_bowl_features, get_feature_columns\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "\n",
        "# Load all our data\n",
        "pbp = load_pbp_cached(seasons=range(2000, 2026))\n",
        "schedules = load_schedules_cached(seasons=range(2000, 2026))\n",
        "madden_raw = pl.read_csv(PROJECT_ROOT / \"assets\" / \"madden_super_bowl.csv\")\n",
        "\n",
        "print(\"‚úÖ Data loaded (2000-2025)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Historical Super Bowls for training (exclude 2025)\n",
        "sb_games = (\n",
        "    schedules\n",
        "    .filter(pl.col(\"game_type\") == \"SB\", pl.col(\"season\") < 2025)\n",
        "    .select([\"season\", \"game_id\", \"home_team\", \"away_team\", \n",
        "             \"home_score\", \"away_score\", \"spread_line\", \"total_line\"])\n",
        "    .with_columns(\n",
        "        pl.when(pl.col(\"home_score\") > pl.col(\"away_score\"))\n",
        "        .then(pl.col(\"home_team\")).otherwise(pl.col(\"away_team\")).alias(\"winner\")\n",
        "    ).collect()\n",
        ")\n",
        "print(f\"üìä Training on {len(sb_games)} historical Super Bowls\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build complete feature matrix\n",
        "sb_features = build_super_bowl_features(\n",
        "    pbp=pbp, schedules=schedules, madden_df=madden_raw, sb_games=sb_games\n",
        ")\n",
        "feature_cols = get_feature_columns()\n",
        "print(f\"‚úÖ {len(feature_cols)} features built\")\n",
        "print(f\"   PBP Features: off_epa_diff, pass_epa_diff, rush_epa_diff, ...\")\n",
        "print(f\"   Madden Features: qb_ovr_diff, avg_ovr_diff, max_ovr_diff\")\n",
        "print(f\"   Market Features: spread_line, total_line, implied_win_prob\")\n",
        "\n",
        "train_data = sb_features.drop_nulls(subset=feature_cols + [\"home_win\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üñêÔ∏è HANDS ON: Polars ‚Üí scikit-learn\n",
        "\n",
        "**Polars integrates directly with scikit-learn!**\n",
        "\n",
        "```python\n",
        "X = train_data.select(features).to_numpy()\n",
        "y = train_data.select(\"winner\").to_numpy().ravel()\n",
        "```\n",
        "\n",
        "This is often a **zero-copy operation** because Polars uses Arrow memory, which NumPy understands.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build the Training Set\n",
        "train_data = sb_features.drop_nulls(subset=feature_cols + [\"home_win\"])\n",
        "\n",
        "X = train_data.select(feature_cols).to_numpy()  # Zero-copy!\n",
        "y = train_data.select(\"home_win\").to_numpy().ravel()\n",
        "\n",
        "print(f\"Training: {X.shape[0]} games √ó {X.shape[1]} features\")\n",
        "print(f\"Home team wins: {y.sum()}/{len(y)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Compare multiple models\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(random_state=42, max_iter=1000, C=0.5),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, max_depth=3, random_state=42),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=50, max_depth=2, random_state=42)\n",
        "}\n",
        "\n",
        "loo = LeaveOneOut()\n",
        "results = {}\n",
        "\n",
        "print(\"üìä Model Comparison (Leave-One-Out CV):\")\n",
        "for name, clf in models.items():\n",
        "    X_use = X_scaled if name == \"Logistic Regression\" else X\n",
        "    preds = [clf.fit(X_use[tr], y[tr]).predict(X_use[te])[0] for tr, te in loo.split(X_use)]\n",
        "    results[name] = np.mean(np.array(preds) == y)\n",
        "    print(f\"   {name}: {results[name]:.1%}\")\n",
        "\n",
        "best_name = max(results, key=results.get)\n",
        "print(f\"\\nüèÜ Best Model: {best_name}\")\n",
        "\n",
        "# Train final model\n",
        "best_model = models[best_name]\n",
        "X_final = X_scaled if best_name == \"Logistic Regression\" else X\n",
        "best_model.fit(X_final, y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Feature Importance\n",
        "\n",
        "**\"Math confirms: The better QB usually wins!\"**\n",
        "\n",
        "Let's see which features the model thinks are most predictive of Super Bowl winners.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get feature importances\n",
        "if hasattr(best_model, 'feature_importances_'):\n",
        "    importances = best_model.feature_importances_\n",
        "else:\n",
        "    importances = np.abs(best_model.coef_[0])\n",
        "\n",
        "# Create DataFrame for visualization\n",
        "feat_df = pl.DataFrame({\n",
        "    \"Feature\": feature_cols,\n",
        "    \"Importance\": importances\n",
        "}).sort(\"Importance\", descending=True)\n",
        "\n",
        "# Add category for coloring\n",
        "def get_category(feat):\n",
        "    if 'ovr' in feat:\n",
        "        return 'Madden Rating'\n",
        "    elif 'spread' in feat or 'total' in feat or 'implied' in feat:\n",
        "        return 'Vegas Market'\n",
        "    else:\n",
        "        return 'PBP/EPA Stats'\n",
        "\n",
        "feat_df = feat_df.with_columns(\n",
        "    pl.col(\"Feature\").map_elements(get_category, return_dtype=pl.Utf8).alias(\"Category\")\n",
        ")\n",
        "\n",
        "# Visualize\n",
        "fig = px.bar(\n",
        "    feat_df.to_pandas(), \n",
        "    x=\"Importance\", \n",
        "    y=\"Feature\",\n",
        "    color=\"Category\",\n",
        "    orientation='h',\n",
        "    title=\"üèà Feature Importance: What Predicts Super Bowl Winners?\",\n",
        "    color_discrete_map={\n",
        "        'PBP/EPA Stats': '#00D084',\n",
        "        'Madden Rating': '#FFB612', \n",
        "        'Vegas Market': '#D50A0A'\n",
        "    }\n",
        ")\n",
        "fig.update_layout(\n",
        "    paper_bgcolor='#0D1117',\n",
        "    plot_bgcolor='#161B22',\n",
        "    font=dict(color='#E6EDF3'),\n",
        "    yaxis={'categoryorder': 'total ascending'},\n",
        "    height=500\n",
        ")\n",
        "fig.show()\n",
        "\n",
        "# Print summary\n",
        "print(\"\\nüìã TOP 5 PREDICTORS:\")\n",
        "for row in feat_df.head(5).iter_rows(named=True):\n",
        "    print(f\"   {row['Feature']}: {row['Importance']:.3f} ({row['Category']})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üèÜ THE BIG REVEAL: Super Bowl 2025\n",
        "\n",
        "### New England Patriots (Home) vs Seattle Seahawks (Away)\n",
        "\n",
        "Let's feed in this year's teams and see who the model predicts!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load Madden 25 ratings for both teams\n",
        "seahawks = pl.read_csv(PROJECT_ROOT / \"data\" / \"current_superbowl\" / \"Scraping Player Data with Python - Seahawks.csv\")\n",
        "patriots = pl.read_csv(PROJECT_ROOT / \"data\" / \"current_superbowl\" / \"Scraping Player Data with Python - Patriots.csv\")\n",
        "\n",
        "# Show QBs\n",
        "sea_qb = seahawks.filter(pl.col(\"Pos\") == \"QB\").sort(\"OVR\", descending=True).head(1)\n",
        "ne_qb = patriots.filter(pl.col(\"Pos\") == \"QB\").sort(\"OVR\", descending=True).head(1)\n",
        "\n",
        "print(\"üèà THE QUARTERBACKS:\")\n",
        "print(f\"   Patriots: {ne_qb['Player'][0]} (Madden OVR: {ne_qb['OVR'][0]})\")\n",
        "print(f\"   Seahawks: {sea_qb['Player'][0]} (Madden OVR: {sea_qb['OVR'][0]})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get 2025 season EPA stats\n",
        "team_stats = (\n",
        "    pbp.filter(pl.col(\"season\") == 2025, pl.col(\"play_type\").is_in([\"pass\", \"run\"]))\n",
        "    .group_by(\"posteam\")\n",
        "    .agg([\n",
        "        pl.col(\"epa\").sum().alias(\"off_epa\"),\n",
        "        pl.col(\"epa\").filter(pl.col(\"play_type\") == \"pass\").sum().alias(\"pass_epa\"),\n",
        "        pl.col(\"epa\").filter(pl.col(\"play_type\") == \"run\").sum().alias(\"rush_epa\"),\n",
        "        (pl.col(\"epa\") > 0).mean().alias(\"success_rate\"),\n",
        "        (pl.col(\"epa\") > 1.5).mean().alias(\"explosive_rate\"),\n",
        "    ]).collect()\n",
        ")\n",
        "def_stats = (\n",
        "    pbp.filter(pl.col(\"season\") == 2025, pl.col(\"play_type\").is_in([\"pass\", \"run\"]))\n",
        "    .group_by(\"defteam\").agg(pl.col(\"epa\").sum().alias(\"def_epa\")).collect()\n",
        ")\n",
        "\n",
        "ne_off = team_stats.filter(pl.col(\"posteam\") == \"NE\")\n",
        "sea_off = team_stats.filter(pl.col(\"posteam\") == \"SEA\")\n",
        "ne_def = def_stats.filter(pl.col(\"defteam\") == \"NE\")\n",
        "sea_def = def_stats.filter(pl.col(\"defteam\") == \"SEA\")\n",
        "\n",
        "ne_qb_ovr = patriots.filter(pl.col(\"Pos\") == \"QB\").select(pl.col(\"OVR\").max()).item()\n",
        "sea_qb_ovr = seahawks.filter(pl.col(\"Pos\") == \"QB\").select(pl.col(\"OVR\").max()).item()\n",
        "\n",
        "print(f\"üìä 2025 SEASON OFFENSE (EPA):\")\n",
        "print(f\"   Patriots: {ne_off['off_epa'][0]:.1f}\")\n",
        "print(f\"   Seahawks: {sea_off['off_epa'][0]:.1f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build feature vector: HOME (NE) - AWAY (SEA)\n",
        "sb_2025_features = np.array([[\n",
        "    ne_off['off_epa'][0] - sea_off['off_epa'][0],\n",
        "    ne_def['def_epa'][0] - sea_def['def_epa'][0],\n",
        "    ne_off['pass_epa'][0] - sea_off['pass_epa'][0],\n",
        "    ne_off['rush_epa'][0] - sea_off['rush_epa'][0],\n",
        "    ne_off['success_rate'][0] - sea_off['success_rate'][0],\n",
        "    ne_off['explosive_rate'][0] - sea_off['explosive_rate'][0],\n",
        "    0.0, 0.0, 0.0, 0.0,  # redzone, 3rd down, turnovers, playoff\n",
        "    ne_qb_ovr - sea_qb_ovr,\n",
        "    patriots.select(pl.col(\"OVR\").mean()).item() - seahawks.select(pl.col(\"OVR\").mean()).item(),\n",
        "    patriots.select(pl.col(\"OVR\").max()).item() - seahawks.select(pl.col(\"OVR\").max()).item(),\n",
        "    2.5, 47.5, 0.48  # spread, total, implied\n",
        "]])\n",
        "\n",
        "sb_2025_scaled = scaler.transform(sb_2025_features) if best_name == \"Logistic Regression\" else sb_2025_features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üèÜ THE MOMENT OF TRUTH!\n",
        "pred = best_model.predict(sb_2025_scaled)\n",
        "prob = best_model.predict_proba(sb_2025_scaled)\n",
        "\n",
        "# Calibrate to avoid extreme probabilities\n",
        "ne_prob_raw = prob[0, 1]\n",
        "ne_prob = 0.15 + 0.70 * ne_prob_raw  # Shrink to [15%, 85%]\n",
        "sea_prob = 1 - ne_prob\n",
        "\n",
        "winner = \"PATRIOTS\" if ne_prob > 0.5 else \"SEAHAWKS\"\n",
        "winner_abbr = \"NE\" if ne_prob > 0.5 else \"SEA\"\n",
        "confidence = max(ne_prob, sea_prob)\n",
        "\n",
        "print(\"\\n\" + \"üèà\" * 20)\n",
        "print(\"\\n    üèÜ SUPER BOWL 2025 PREDICTION üèÜ\")\n",
        "print(f\"    Model: {best_name}\")\n",
        "print(\"\\n\" + \"üèà\" * 20)\n",
        "print(f\"\\n  New England Patriots vs Seattle Seahawks\")\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(f\"\\n  Patriots: {ne_prob:.1%}\")\n",
        "print(f\"  Seahawks: {sea_prob:.1%}\")\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(f\"\\n  üèÜ PREDICTED WINNER: {winner}\")\n",
        "print(f\"     Confidence: {confidence:.1%}\")\n",
        "print(\"\\n\" + \"üèà\" * 20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate explanation using Ollama\n",
        "print(\"\\nüìù PREDICTION EXPLANATION:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Build context\n",
        "if hasattr(best_model, 'coef_'):\n",
        "    contributions = {feature_cols[i]: float(best_model.coef_[0][i] * sb_2025_scaled[0][i])\n",
        "                     for i in range(len(feature_cols))}\n",
        "else:\n",
        "    contributions = {feature_cols[i]: float(best_model.feature_importances_[i] * sb_2025_features[0][i])\n",
        "                     for i in range(len(feature_cols))}\n",
        "\n",
        "ctx = {\n",
        "    \"home_team\": \"NE\",\n",
        "    \"away_team\": \"SEA\",\n",
        "    \"predicted_winner\": winner_abbr,\n",
        "    \"confidence\": confidence,\n",
        "    \"contributions\": contributions\n",
        "}\n",
        "\n",
        "try:\n",
        "    from llm_explainer import explain_with_ollama\n",
        "    explanation = explain_with_ollama(ctx, model=\"llama3.2\")\n",
        "    print(explanation)\n",
        "except Exception as e:\n",
        "    print(f\"(Ollama: {e})\")\n",
        "    winner_name = \"New England\" if winner_abbr == \"NE\" else \"Seattle\"\n",
        "    loser_name = \"Seattle\" if winner_abbr == \"NE\" else \"New England\"\n",
        "    print(f\"\\n{winner_name} holds a {confidence:.0%} edge over {loser_name}.\")\n",
        "    print(\"\\nKey factors:\")\n",
        "    for feat, val in sorted(contributions.items(), key=lambda x: abs(x[1]), reverse=True)[:3]:\n",
        "        print(f\"  ‚Ä¢ {feat.replace('_diff','').replace('_',' ').title()}: {abs(val):.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Win probability visualization\n",
        "fig = go.Figure(go.Indicator(\n",
        "    mode=\"gauge+number\",\n",
        "    value=ne_prob * 100,\n",
        "    title={'text': f\"Patriots Win Probability\", 'font': {'size': 24, 'color': '#E6EDF3'}},\n",
        "    number={'suffix': '%', 'font': {'size': 48}},\n",
        "    gauge={\n",
        "        'axis': {'range': [0, 100]},\n",
        "        'bar': {'color': '#002244'},\n",
        "        'steps': [\n",
        "            {'range': [0, 40], 'color': '#69BE28'},\n",
        "            {'range': [40, 60], 'color': '#A5ACAF'},\n",
        "            {'range': [60, 100], 'color': '#002244'}\n",
        "        ],\n",
        "        'threshold': {'line': {'color': '#C60C30', 'width': 4}, 'value': 50}\n",
        "    }\n",
        "))\n",
        "fig.update_layout(paper_bgcolor='#0D1117', font={'color': '#E6EDF3'}, height=400)\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Takeaways\n",
        "\n",
        "We just processed **25 years of NFL data**, joined disparate datasets, cleaned strings, and trained a model‚Äîall in 40 minutes, on a laptop!\n",
        "\n",
        "If you tried this in Excel, it would crash. In Pandas, you'd be waiting for loading bars. In Polars, it was **instant**.\n",
        "\n",
        "**Key Lessons:**\n",
        "1. Use `LazyFrames` (`scan_parquet`) for big data\n",
        "2. Use Expressions (`pl.col()`) for readable logic\n",
        "3. `.to_numpy()` integrates seamlessly with scikit-learn\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
