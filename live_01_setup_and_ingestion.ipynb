{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Super Bowl Analytics with Polars\n",
                "\n",
                "## Module 0 & 1: Environment Setup & Data Ingestion\n",
                "\n",
                "Welcome to the **DataCamp Code-Along: Super Bowl Analytics with Polars**! \n",
                "\n",
                "In this session, we'll embark to answer the ultimate question:\n",
                "\n",
                "> **\"Can we mathematically predict the Super Bowl winner?\"**\n",
                "\n",
                "### Why Polars?\n",
                "\n",
                "We're using **Polars** instead of Pandas for several compelling reasons:\n",
                "\n",
                "- **10-30x faster** for common data operations\n",
                "- **Memory efficient** - works with massive NFL datasets on laptops\n",
                "- **Modern API** - functional, expression-based syntax\n",
                "- **Lazy evaluation** - query optimization like a SQL engine\n",
                "\n",
                "Let's get started!\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Verify Dependencies\n",
                "\n",
                "First, let's ensure all required packages are installed:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check package versions\n",
                "import sys\n",
                "\n",
                "print(f\"Python version: {sys.version}\")\n",
                "\n",
                "# Core packages\n",
                "import polars as pl\n",
                "print(f\"Polars version: {pl.__version__}\")\n",
                "\n",
                "import pyarrow\n",
                "print(f\"PyArrow version: {pyarrow.__version__}\")\n",
                "\n",
                "# NFL data\n",
                "import nflreadpy as nfl\n",
                "print(f\"nflreadpy loaded successfully\")\n",
                "\n",
                "# Visualization\n",
                "import plotly\n",
                "print(f\"Plotly version: {plotly.__version__}\")\n",
                "\n",
                "# ML\n",
                "import sklearn\n",
                "print(f\"scikit-learn version: {sklearn.__version__}\")\n",
                "\n",
                "print(\"\\n‚úÖ All dependencies loaded successfully!\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Project Setup\n",
                "\n",
                "Our project follows data engineering best practices:\n",
                "\n",
                "```\n",
                "NFL Analytics/\n",
                "‚îú‚îÄ‚îÄ data/\n",
                "‚îÇ   ‚îú‚îÄ‚îÄ raw/           # Immutable source data\n",
                "‚îÇ   ‚îî‚îÄ‚îÄ processed/     # Transformed checkpoints\n",
                "‚îú‚îÄ‚îÄ src/               # Reusable Python modules\n",
                "‚îú‚îÄ‚îÄ assets/            # Static files (Madden ratings)\n",
                "‚îî‚îÄ‚îÄ notebooks/         # Analysis notebooks\n",
                "```\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pathlib import Path\n",
                "import os\n",
                "import time\n",
                "\n",
                "# Set up project root\n",
                "current_path = Path.cwd()\n",
                "if not (current_path / \"src\").exists() and (current_path.parent / \"src\").exists():\n",
                "    os.chdir(current_path.parent)\n",
                "\n",
                "PROJECT_ROOT = Path.cwd()\n",
                "\n",
                "# Add src to path for imports\n",
                "sys.path.insert(0, str(PROJECT_ROOT / \"src\"))\n",
                "\n",
                "print(f\"Project root: {PROJECT_ROOT}\")\n",
                "print(\"\\nDirectory structure:\")\n",
                "for item in sorted(PROJECT_ROOT.iterdir()):\n",
                "    if not item.name.startswith(\".\"):\n",
                "        icon = \"üìÅ\" if item.is_dir() else \"üìÑ\"\n",
                "        print(f\"  {icon} {item.name}\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import our custom modules\n",
                "from ingestion import load_pbp_cached, load_schedules_cached, load_players_cached, load_super_bowl_games\n",
                "from cleaning import normalize_player_name, standardize_team_abbr\n",
                "from features import epa_above_avg, rolling_epa, qb_season_stats\n",
                "from viz import plot_epa_evolution, apply_dark_theme\n",
                "\n",
                "print(\"‚úÖ Custom modules loaded successfully!\")\n",
                "print(\"\\nAvailable functions:\")\n",
                "print(\"  - ingestion: load_pbp_cached, load_schedules_cached, load_super_bowl_games\")\n",
                "print(\"  - cleaning: normalize_player_name, standardize_team_abbr\")\n",
                "print(\"  - features: epa_above_avg, rolling_epa, qb_season_stats\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 3. Entering the NFLverse\n",
                "\n",
                "We're using data from the **NFLverse** ‚Äî a massive community effort led by Ben Baldwin, Sebastian Carl, Lee Sharpe, Tan Ho, and John Edwards to make NFL analytics accessible to everyone.\n",
                "\n",
                "### Key Concept: LazyFrames\n",
                "\n",
                "In Polars, we use `pl.scan_parquet()` instead of loading data directly.\n",
                "\n",
                "**This does NOT load the data.** It creates a `LazyFrame` ‚Äî think of it like a query plan.\n",
                "\n",
                "Polars looks at your file, notes the schema, and **waits**. It won't actually touch the data until we ask for a result.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load PBP data - this creates a LazyFrame, NOT loaded into memory yet!\n",
                "start_time = time.time()\n",
                "\n",
                "pbp = load_pbp_cached(seasons=range(2000, 2026))\n",
                "\n",
                "elapsed = time.time() - start_time\n",
                "print(f\"‚è±Ô∏è Reference created in: {elapsed:.2f} seconds\")\n",
                "print(f\"\\nThis is a: {type(pbp).__name__}\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. The Schema: Type Safety\n",
                "\n",
                "**This is a key difference from Pandas.**\n",
                "\n",
                "In Pandas, you might get 'Object' columns that are a mix of strings and integers, which causes bugs.\n",
                "\n",
                "Polars forces you to be disciplined ‚Äî every column has a strict type. This saves you hours of debugging later.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Look at the schema - Polars is STRICT about types\n",
                "schema = pbp.collect_schema()\n",
                "\n",
                "print(f\"Total columns: {len(schema)}\")\n",
                "print(\"\\nKey columns with their types:\")\n",
                "print(\"-\" * 40)\n",
                "\n",
                "key_cols = [\"game_id\", \"season\", \"week\", \"posteam\", \"defteam\", \"epa\", \"wpa\", \"passer\", \"play_type\"]\n",
                "for col in key_cols:\n",
                "    if col in schema:\n",
                "        print(f\"  {col:20s} {str(schema[col])}\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Polars vs Pandas: Speed Test üèéÔ∏è\n",
                "\n",
                "Here's the magic: Polars optimizes EVERYTHING before touching the data.\n",
                "\n",
                "Let's compare **Polars** vs **Pandas** on the same operation:\n",
                "- Filter to passing plays only\n",
                "- Select 5 columns\n",
                "\n",
                "**Watch the difference!**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# üêº PANDAS: Eager loading - loads EVERYTHING first\n",
                "import pyarrow.parquet as pq\n",
                "import pyarrow as pa\n",
                "\n",
                "print(\"üêº PANDAS: Loading and filtering...\")\n",
                "start_pandas = time.time()\n",
                "\n",
                "# Load with PyArrow and cast dictionary columns\n",
                "arrow_table = pq.read_table(PROJECT_ROOT / \"data\" / \"raw\" / \"pbp_slim.parquet\")\n",
                "\n",
                "new_schema = []\n",
                "for field in arrow_table.schema:\n",
                "    if pa.types.is_dictionary(field.type):\n",
                "        new_schema.append(pa.field(field.name, field.type.value_type))\n",
                "    else:\n",
                "        new_schema.append(field)\n",
                "\n",
                "arrow_table = arrow_table.cast(pa.schema(new_schema))\n",
                "pandas_df = arrow_table.to_pandas()\n",
                "\n",
                "# Then filter to passing plays\n",
                "pandas_passing = pandas_df[\n",
                "    (pandas_df[\"play_type\"] == \"pass\") & \n",
                "    (pandas_df[\"passer_id\"].notna())\n",
                "][[\"game_id\", \"season\", \"passer\", \"epa\", \"cpoe\"]]\n",
                "\n",
                "pandas_time = time.time() - start_pandas\n",
                "print(f\"‚è±Ô∏è Pandas time: {pandas_time:.2f} seconds\")\n",
                "print(f\"   Rows: {len(pandas_passing):,}\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# üêª‚Äç‚ùÑÔ∏è POLARS: Lazy evaluation - builds a plan, then executes optimally\n",
                "print(\"üêª‚Äç‚ùÑÔ∏è POLARS: Building query plan and executing...\")\n",
                "start_polars = time.time()\n",
                "\n",
                "# Build the lazy query (this is instant - just a plan!)\n",
                "passing_query = (\n",
                "    pbp\n",
                "    .filter(\n",
                "        pl.col(\"play_type\") == \"pass\",\n",
                "        pl.col(\"passer_id\").is_not_null()\n",
                "    )\n",
                "    .select([\"game_id\", \"season\", \"passer\", \"epa\", \"cpoe\"])\n",
                ")\n",
                "\n",
                "# Execute with .collect()\n",
                "passing_plays = passing_query.collect()\n",
                "\n",
                "polars_time = time.time() - start_polars\n",
                "print(f\"‚è±Ô∏è Polars time: {polars_time:.4f} seconds\")\n",
                "print(f\"   Rows: {len(passing_plays):,}\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# üèÜ THE VERDICT\n",
                "speedup = pandas_time / polars_time if polars_time > 0 else float('inf')\n",
                "\n",
                "print(\"\\n\" + \"=\" * 50)\n",
                "print(\"  üèÜ SPEED COMPARISON RESULTS\")\n",
                "print(\"=\" * 50)\n",
                "print(f\"\\n  üêº Pandas:  {pandas_time:.3f} seconds\")\n",
                "print(f\"  üêª‚Äç‚ùÑÔ∏è Polars:  {polars_time:.3f} seconds\")\n",
                "print(f\"\\n  üöÄ Polars is {speedup:.1f}x FASTER!\")\n",
                "print(\"\\n\" + \"=\" * 50)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# WHY is Polars faster? Let's look at the query plan\n",
                "print(\"Why is Polars faster? Look at the optimized query plan:\")\n",
                "print(\"=\" * 50)\n",
                "print(passing_query.explain())\n",
                "print(\"=\" * 50)\n",
                "print(\"\\nüëÜ Polars only reads the 5 columns we need!\")\n",
                "print(\"   Pandas loaded ALL 30 columns, then threw most away.\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Loading Schedule & Super Bowl Data\n",
                "\n",
                "The schedule data contains game-level metadata:\n",
                "- Final scores\n",
                "- Betting lines (spread, total)\n",
                "- Game type (regular season, playoffs, **Super Bowl**)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load schedule data\n",
                "schedules = load_schedules_cached(seasons=range(2000, 2026))\n",
                "\n",
                "# Filter to Super Bowl games only\n",
                "super_bowls = load_super_bowl_games(schedules)\n",
                "sb_df = super_bowls.collect()\n",
                "\n",
                "print(f\"Super Bowls in dataset: {len(sb_df)}\")\n",
                "print(\"\\nRecent Super Bowls:\")\n",
                "sb_df.select([\n",
                "    \"season\", \"game_id\", \"home_team\", \"away_team\", \n",
                "    \"home_score\", \"away_score\", \"spread_line\"\n",
                "]).tail(10)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Understanding EPA (Expected Points Added)\n",
                "\n",
                "**EPA** is *the* foundational metric for modern NFL analytics.\n",
                "\n",
                "Imagine it's 1st & 10 at your own 20. Historical data says you're expected to score ~0.5 points on this drive.\n",
                "\n",
                "- **Play A:** You run for 30 yards to midfield. Expected points jumps to ~2.5. **EPA = +2.0**\n",
                "- **Play B:** You throw an interception. Expected points drops to -3. **EPA = -3.5**\n",
                "\n",
                "It assigns a concrete value to every single play based on context (down, distance, field position).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Quick data quality check\n",
                "print(\"üìä DATA QUALITY SUMMARY\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "seasons = pbp.select(\"season\").unique().collect()[\"season\"].to_list()\n",
                "print(f\"\\n‚úÖ Seasons covered: {min(seasons)} - {max(seasons)}\")\n",
                "\n",
                "total_plays = pbp.select(pl.len()).collect().item()\n",
                "print(f\"‚úÖ Total plays: {total_plays:,}\")\n",
                "\n",
                "print(f\"‚úÖ Super Bowls: {len(sb_df)}\")\n",
                "\n",
                "print(\"\\n\" + \"=\" * 50)\n",
                "print(\"Data is ready! Next: Era of the Quarterback ‚Üí\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Next Steps\n",
                "\n",
                "We've successfully set up and loaded our core datasets! In the next notebook, we'll:\n",
                "\n",
                "1. **Analyze the evolution of passing** in the NFL\n",
                "2. **Visualize the \"Era of the Quarterback\"**\n",
                "3. **TYPE ALONG** ‚Äî Build a Polars query together!\n",
                "\n",
                "Continue to **[02_era_of_the_quarterback.ipynb](live_02_era_of_the_quarterback.ipynb)** ‚Üí\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.13.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}